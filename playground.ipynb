{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from random import choice\n",
    "from torch import empty\n",
    "\n",
    "from generate_data import generate_data\n",
    "from Modules import Sequential, Linear, ReLU, Tanh, Sigmoid, LossMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2])\n",
      "tensor(1.0000)\n",
      "tensor(-1.3313e-07)\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "train_input, train_target, test_input, test_target = generate_data(1000, True)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(train_input.std())\n",
    "print(train_input.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9496, -0.0000],\n",
      "        [1.6129, 1.5926],\n",
      "        [-0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, 1.5042],\n",
      "        [-0.0000, -0.0000],\n",
      "        [1.5637, -0.0000]])\n",
      "tensor([[ 1.6827, -0.0000],\n",
      "        [ 0.7218, -1.5687],\n",
      "        [ 0.0000, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.6197],\n",
      "        [-0.0000, -0.0000],\n",
      "        [-0.3193,  0.0000]])\n",
      "ReLU has no parameters\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "r = ReLU()\n",
    "print(r.forward(train_input))\n",
    "print(r.backward(test_input))\n",
    "print(r.param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7396, -0.5365],\n",
      "        [ 0.9236,  0.9205],\n",
      "        [-0.7399, -0.8757],\n",
      "        ...,\n",
      "        [-0.8640,  0.9059],\n",
      "        [-0.7925, -0.3524],\n",
      "        [ 0.9160, -0.4704]])\n",
      "tensor([[ 0.7622, -1.0633],\n",
      "        [ 0.1061, -0.2394],\n",
      "        [ 0.3852, -0.2159],\n",
      "        ...,\n",
      "        [ 0.0949,  0.1111],\n",
      "        [-0.2550, -0.4211],\n",
      "        [-0.0514,  0.8304]])\n",
      "Tanh has no parameters\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "t = Tanh()\n",
    "print(t.forward(train_input))\n",
    "print(t.backward(test_input))\n",
    "print(t.param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7210, 0.3545],\n",
      "        [0.8338, 0.8310],\n",
      "        [0.2788, 0.2047],\n",
      "        ...,\n",
      "        [0.2127, 0.8182],\n",
      "        [0.2539, 0.4090],\n",
      "        [0.8269, 0.3751]])\n",
      "tensor([[ 0.3385, -0.3417],\n",
      "        [ 0.1000, -0.2203],\n",
      "        [ 0.1711, -0.1508],\n",
      "        ...,\n",
      "        [ 0.0627,  0.0922],\n",
      "        [-0.1299, -0.1162],\n",
      "        [-0.0457,  0.2499]])\n",
      "Sigmoid has no parameters\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "s = Sigmoid()\n",
    "print(s.forward(train_input))\n",
    "print(s.backward(test_input))\n",
    "print(s.param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.0844e-01,  2.6811e+00, -1.0228e+11])\n",
      "tensor([1.6715, 0.0437])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 0.6341,  0.1745],\n",
       "          [ 2.4289,  2.1635],\n",
       "          [-1.5185,  1.2460]]), tensor([[ 0.9817,  1.6720],\n",
       "          [-0.0148, -0.0252],\n",
       "          [-0.0964, -0.1642]])),\n",
       " (tensor([ 0.0000e+00,  0.0000e+00, -1.0228e+11]),\n",
       "  tensor([ 2.2386, -0.0338, -0.2199]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Linear(2, 3)\n",
    "\n",
    "print(l.forward(empty(2).normal_()))\n",
    "print(l.backward(empty(3).normal_()))\n",
    "l.param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1., -1.,  1., -1., -1., -1.,  1., -1.])\n",
      "tensor([0., 0., 0., 0.])\n",
      "ReLU has no parameters\n",
      "Tanh has no parameters\n",
      "[[(tensor([[-1.2932,  1.7220,  1.3881, -0.7056],\n",
      "        [-0.9080,  0.0234,  0.2244, -0.1977],\n",
      "        [-0.9730,  0.3552,  1.1050,  0.0940],\n",
      "        [ 0.5398,  0.6748,  1.1153, -1.4859],\n",
      "        [ 1.7217, -1.2040, -0.0773, -0.3395],\n",
      "        [-1.0466, -0.3869, -1.0521,  0.3376]]), tensor([[-0., 0., 0., 0.],\n",
      "        [-0., 0., 0., 0.],\n",
      "        [-0., 0., 0., 0.],\n",
      "        [-0., 0., 0., 0.],\n",
      "        [-0., 0., 0., 0.],\n",
      "        [-0., 0., 0., 0.]])), (tensor([6.0022e+31, 4.2964e+24, 7.5555e+31, 1.1703e-19, 1.5637e-01, 1.1824e+22]), tensor([0., 0., 0., 0., 0., 0.]))], None, [(tensor([[-1.3878, -0.8782,  0.9062, -0.5198, -0.2773, -0.2306],\n",
      "        [ 0.6775,  0.2731, -0.9427,  1.3577,  1.0647, -0.5824],\n",
      "        [-0.5448, -0.3833,  0.7282, -0.2341,  2.1450,  1.1468],\n",
      "        [-0.0872,  0.3840, -0.3850,  0.1755, -0.5099,  0.7178],\n",
      "        [-1.0055,  1.7942, -1.1874,  0.6522, -0.3213, -0.1100],\n",
      "        [-2.0756, -0.8376, -0.9853,  0.9210,  0.2114, -1.7840],\n",
      "        [ 1.1927,  0.7211, -0.4881,  0.2749,  1.8263, -2.5760],\n",
      "        [ 0.4412, -0.3253, -0.5062,  1.1112, -0.0918,  0.2488]]), tensor([[0., 0., 0., -0., -0., 0.],\n",
      "        [0., 0., 0., -0., -0., 0.],\n",
      "        [-0., -0., -0., 0., 0., -0.],\n",
      "        [0., 0., 0., -0., -0., 0.],\n",
      "        [0., 0., 0., -0., -0., 0.],\n",
      "        [0., 0., 0., -0., -0., 0.],\n",
      "        [0., 0., 0., -0., -0., 0.],\n",
      "        [-0., -0., -0., 0., 0., -0.]])), (tensor([0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., -0., 0., 0., 0., 0., -0.]))], None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Linear(4x6) => ReLU => Linear(6x8) => Tanh'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = Linear(4,6)\n",
    "r1 = ReLU()\n",
    "l2 = Linear(6, 8)\n",
    "t2 = Tanh()\n",
    "\n",
    "S = Sequential(l1, r1, l2, t2)\n",
    "print(S.forward(empty(4).normal_()))\n",
    "print(S.backward(empty(8).normal_()))\n",
    "print(S.param())\n",
    "S.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(target):\n",
    "    ohe_target = empty(target.shape[0], 2)\n",
    "    ohe_target[:, 0] = train_target == 0\n",
    "    ohe_target[:, 1] = train_target == 1\n",
    "    return ohe_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_SGD(model, train_input, train_target, nb_epoch = 10000):\n",
    "    nb_train_samples = train_input.shape[0]\n",
    "    ohe_train_target = one_hot_encode(train_target)\n",
    "    mse = LossMSE()\n",
    "    eta = 1e-1 / nb_train_samples\n",
    "    for epoch in range(nb_epoch):\n",
    "        n = choice(range(nb_train_samples))\n",
    "        # Run forward pass\n",
    "        output = model.forward(train_input[n])\n",
    "\n",
    "        # Compute loss\n",
    "        loss = mse.compute_loss(output, ohe_train_target[n])\n",
    "\n",
    "        # Run back propagation\n",
    "        model.backward(mse.backward())\n",
    "        \n",
    "        model.update_param(eta)\n",
    "\n",
    "        # Log the loss\n",
    "        if (epoch % 100 == 0):\n",
    "            print(f\"Epoch : {epoch}, Loss : {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Linear(2,25)\n",
    "a1 = ReLU()\n",
    "l2 = Linear(25, 25)\n",
    "a2 = Tanh()\n",
    "l3 = Linear(25, 25)\n",
    "a3 = Sigmoid()\n",
    "l4 = Linear(25, 2)\n",
    "\n",
    "model = Sequential(l1, a1, l2, a2, l3, a3, l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Loss : 3.0267820358276367\n",
      "Epoch : 100, Loss : 18.4509334564209\n",
      "Epoch : 200, Loss : 15.403722763061523\n",
      "Epoch : 300, Loss : 12.540345191955566\n",
      "Epoch : 400, Loss : 0.5148259401321411\n",
      "Epoch : 500, Loss : 3.6549530029296875\n",
      "Epoch : 600, Loss : 5.363900661468506\n",
      "Epoch : 700, Loss : 0.5512146353721619\n",
      "Epoch : 800, Loss : 2.7910304069519043\n",
      "Epoch : 900, Loss : 0.07498374581336975\n",
      "Epoch : 1000, Loss : 0.22721083462238312\n",
      "Epoch : 1100, Loss : 0.8243176341056824\n",
      "Epoch : 1200, Loss : 0.8627876043319702\n",
      "Epoch : 1300, Loss : 3.4397644996643066\n",
      "Epoch : 1400, Loss : 0.03304024785757065\n",
      "Epoch : 1500, Loss : 0.9418724775314331\n",
      "Epoch : 1600, Loss : 1.1240551471710205\n",
      "Epoch : 1700, Loss : 1.6532535552978516\n",
      "Epoch : 1800, Loss : 0.9338143467903137\n",
      "Epoch : 1900, Loss : 0.38969096541404724\n",
      "Epoch : 2000, Loss : 0.7475508451461792\n",
      "Epoch : 2100, Loss : 3.6028199195861816\n",
      "Epoch : 2200, Loss : 1.0302551984786987\n",
      "Epoch : 2300, Loss : 0.3700354993343353\n",
      "Epoch : 2400, Loss : 0.39728009700775146\n",
      "Epoch : 2500, Loss : 0.8776348233222961\n",
      "Epoch : 2600, Loss : 2.4776499271392822\n",
      "Epoch : 2700, Loss : 0.5871479511260986\n",
      "Epoch : 2800, Loss : 0.2741108238697052\n",
      "Epoch : 2900, Loss : 0.28915977478027344\n",
      "Epoch : 3000, Loss : 0.4691358208656311\n",
      "Epoch : 3100, Loss : 0.19320353865623474\n",
      "Epoch : 3200, Loss : 0.6876954436302185\n",
      "Epoch : 3300, Loss : 0.5826027393341064\n",
      "Epoch : 3400, Loss : 0.0012807066086679697\n",
      "Epoch : 3500, Loss : 0.5471685528755188\n",
      "Epoch : 3600, Loss : 0.44591325521469116\n",
      "Epoch : 3700, Loss : 0.6735220551490784\n",
      "Epoch : 3800, Loss : 1.6245076656341553\n",
      "Epoch : 3900, Loss : 0.46299707889556885\n",
      "Epoch : 4000, Loss : 0.47594958543777466\n",
      "Epoch : 4100, Loss : 0.3050591051578522\n",
      "Epoch : 4200, Loss : 1.5869114398956299\n",
      "Epoch : 4300, Loss : 0.3690650761127472\n",
      "Epoch : 4400, Loss : 0.3893100321292877\n",
      "Epoch : 4500, Loss : 0.5315964221954346\n",
      "Epoch : 4600, Loss : 0.15788161754608154\n",
      "Epoch : 4700, Loss : 0.5820908546447754\n",
      "Epoch : 4800, Loss : 0.16075366735458374\n",
      "Epoch : 4900, Loss : 0.42000657320022583\n",
      "Epoch : 5000, Loss : 0.1467837244272232\n",
      "Epoch : 5100, Loss : 0.9363774061203003\n",
      "Epoch : 5200, Loss : 0.5061776041984558\n",
      "Epoch : 5300, Loss : 0.7951566576957703\n",
      "Epoch : 5400, Loss : 0.18911314010620117\n",
      "Epoch : 5500, Loss : 0.001168065587989986\n",
      "Epoch : 5600, Loss : 0.0536358505487442\n",
      "Epoch : 5700, Loss : 0.058852776885032654\n",
      "Epoch : 5800, Loss : 0.2393328845500946\n",
      "Epoch : 5900, Loss : 0.08452349156141281\n",
      "Epoch : 6000, Loss : 0.4276607036590576\n",
      "Epoch : 6100, Loss : 0.18925823271274567\n",
      "Epoch : 6200, Loss : 0.1599690318107605\n",
      "Epoch : 6300, Loss : 0.07476098835468292\n",
      "Epoch : 6400, Loss : 0.805580735206604\n",
      "Epoch : 6500, Loss : 0.5257289409637451\n",
      "Epoch : 6600, Loss : 0.3078259825706482\n",
      "Epoch : 6700, Loss : 0.02783924527466297\n",
      "Epoch : 6800, Loss : 0.07629656791687012\n",
      "Epoch : 6900, Loss : 0.32392454147338867\n",
      "Epoch : 7000, Loss : 0.9507769346237183\n",
      "Epoch : 7100, Loss : 0.8268705606460571\n",
      "Epoch : 7200, Loss : 0.07599006593227386\n",
      "Epoch : 7300, Loss : 0.0054299538023769855\n",
      "Epoch : 7400, Loss : 0.2655424475669861\n",
      "Epoch : 7500, Loss : 0.2435857206583023\n",
      "Epoch : 7600, Loss : 0.08580330014228821\n",
      "Epoch : 7700, Loss : 0.1950322985649109\n",
      "Epoch : 7800, Loss : 0.32030048966407776\n",
      "Epoch : 7900, Loss : 0.4793315529823303\n",
      "Epoch : 8000, Loss : 0.15196101367473602\n",
      "Epoch : 8100, Loss : 0.11819659173488617\n",
      "Epoch : 8200, Loss : 1.2627261877059937\n",
      "Epoch : 8300, Loss : 0.012080762535333633\n",
      "Epoch : 8400, Loss : 0.27398303151130676\n",
      "Epoch : 8500, Loss : 0.20271655917167664\n",
      "Epoch : 8600, Loss : 0.19852082431316376\n",
      "Epoch : 8700, Loss : 0.41046878695487976\n",
      "Epoch : 8800, Loss : 0.2642129361629486\n",
      "Epoch : 8900, Loss : 0.12632909417152405\n",
      "Epoch : 9000, Loss : 0.00637445505708456\n",
      "Epoch : 9100, Loss : 0.4000319540500641\n",
      "Epoch : 9200, Loss : 0.04860555753111839\n",
      "Epoch : 9300, Loss : 0.15339967608451843\n",
      "Epoch : 9400, Loss : 0.25610315799713135\n",
      "Epoch : 9500, Loss : 0.542210578918457\n",
      "Epoch : 9600, Loss : 0.5749751329421997\n",
      "Epoch : 9700, Loss : 0.1827402412891388\n",
      "Epoch : 9800, Loss : 0.19994685053825378\n",
      "Epoch : 9900, Loss : 0.010656493715941906\n"
     ]
    }
   ],
   "source": [
    "train_model_SGD(model, train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, input, target):\n",
    "    output = empty(input.shape[0], 2)\n",
    "    for n in range(output.shape[0]):\n",
    "        output[n] = model.forward(train_input[n])\n",
    "    return (output.argmax(1) == target).sum() / float(output.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9680)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5770)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model, test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
